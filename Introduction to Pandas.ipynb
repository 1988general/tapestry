{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Pandas?\n",
    "---\n",
    "\n",
    "From https://pandas.pydata.org/pandas-docs/stable:\n",
    "\n",
    "> pandas is a Python package providing fast, flexible, and expressive data structures designed to\n",
    "> make working with “relational” or “labeled” data both easy and intuitive. It aims to be the\n",
    "> fundamental high-level building block for doing practical, real world data analysis in Python.\n",
    "> Additionally, it has the broader goal of becoming the most powerful and flexible open source data\n",
    "> analysis / manipulation tool available in any language. It is already well on its way toward this\n",
    "> goal.\n",
    "\n",
    "I tend to use Pandas to work with tabular data, similar to columns and rows in an Excel spreadsheet. However, what do you do if your data no longer fits in an Excel sheet? Use Pandas.\n",
    "\n",
    "Pandas is built on top of NumPy, a lower level numerical computing library with a fast multidimensional array object. I decided to forgo an introduction to NumPy because learning Pandas will provide you many of the fundamentals of NumPy. Let's start by looking at the fundamental data structures in Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Pandas\n",
    "---\n",
    "\n",
    "First, you need to `import pandas`. By convention, it is imported with the shorter library name `pd`. That is done with the following syntax:\n",
    "\n",
    "```python\n",
    "import <library> as <short name>\n",
    "```\n",
    "\n",
    "#### Tasks:\n",
    "\n",
    "1. Import pandas using the short name convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Data Structures\n",
    "---\n",
    "\n",
    "Similar to the basic Python data structures (e.g. `list, dictionary, set`), Pandas is built on top of three fundamental data structures:\n",
    "\n",
    "1. `Series`: For one-dimensional data, similar to a `list` or NumPy array\n",
    "2. `DataFrame`: For two-dimensional data, similar to a `dictionary` or 2d NumPy Array\n",
    "3. `Index`: Similar to a `Series`, but for naming, selecting, and transforming data within a `Series` or `DataFrame`\n",
    "\n",
    "### Series\n",
    "\n",
    "You can create pandas `Series` in a few ways:\n",
    "\n",
    "- From a named Python list:\n",
    "```python\n",
    "a = ['a', 'b', 'c']\n",
    "series = pd.Series(a)\n",
    "```\n",
    "- Or, from a temporary Python list:\n",
    "```python\n",
    "series = pd.Series([4, 5, 6])\n",
    "```\n",
    "- Or, using specific index (similar to `dict`, keys are index, values are list):\n",
    "```python\n",
    "series = pd.Series([4, 5, 6], index=['a', 'b', 'c'])\n",
    "```\n",
    "- Or, directly from a dictionary (exactly the same as above):\n",
    "```python\n",
    "series = pd.Series({'a': 4, 'b': 5, 'c': 6})\n",
    "```\n",
    "\n",
    "### DataFrame\n",
    "\n",
    "This is the data structure that makes Pandas so powerful. A `DataFrame` is essentially built from many `Series` objects. A `Series` is very similar to a `dict`, the `index` are keys each of which have a value. In a `DataFrame`, the `keys` map to `Series` objects which share a common `index`. An example:\n",
    "\n",
    "```python\n",
    "rock_bands = ['Pink Floyd', 'Rush', 'Yes']\n",
    "year_formed = [1965, 1968, 1968]\n",
    "location_formed = ['London, England', 'Ontario, Canada', 'London, England']\n",
    "df = pd.DataFrame({'year_formed': year_formed, 'location_formed': location_formed}, index=rock_bands)\n",
    "```\n",
    "\n",
    "Additionally, `DataFrame`'s can be constructed from files! In one of the previous tasks, you were asked to read a bar separated values (bsv) file, parse it manually, and rewrite it to comma separated values (csv). This was a ridiculous task and could have been completed with 2 lines of pandas! Reminder, these files don't contain headers!\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('gpu.bsv', sep='|', header=None)\n",
    "df.to_csv('gpu.csv', sep=',', header=None, index=None)\n",
    "```\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Use `pd.read_csv` to read in the csv file: `example.csv`. It does not contain a header. Call the variable `df`. By default `pd.read_csv` sets the seperator (`sep`) to a comma. Add `names=['col1', 'col2', 'col3']` to the list of arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing DataFrames\n",
    "---\n",
    "\n",
    "Jupyter has built in support for viewing `DataFrame` objects in a nice format. Run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have seen 4 rows and 4 columns. The upper most row are the `keys` and the most left column are the `index`. Think of each column as 3 `Series` objects. The following code snippet won't run, but it is meant to help you think about the `DataFrame` above:\n",
    "\n",
    "```python\n",
    "df['col1'] = pd.Series([1, 4, 7])\n",
    "df['col2'] = pd.Series([2, 5, 8])\n",
    "df['col3'] = pd.Series([3, 6, 9])\n",
    "```\n",
    "\n",
    "If you only want to view a subset of your DataFrame, you can use `df.head()`. By default it will print 5 rows at the top of your DataFrame. You can change the default w/ `df.head(n=<number>)`\n",
    "\n",
    "Tasks\n",
    "---\n",
    "\n",
    "1. Try printing the `head` of `df`, does it look different from the previous code cell? Why?\n",
    "2. Print only the first row of `df` using `head`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access and Types\n",
    "\n",
    "You can access a DataFrame in 2 ways:\n",
    "\n",
    "1. `df['<key>']` where `<key>` in the above `df` could be `col1` or `col2` or `col3`\n",
    "2. Or, `df.<key>`\n",
    "\n",
    "You can access the types of columns with `df.dtypes`\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Access `col2` of `df` using both the `dict` style and attribute style.\n",
    "2. Why are there 2 columns printed?\n",
    "3. What is the type of `df.col2`?\n",
    "4. What are the `dtypes` of `df`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing and Indexing\n",
    "---\n",
    "\n",
    "There are many ways to slice and dice DataFrames. Let's start with the least flexible option, selecting multiple columns. Let's make a new DataFrame in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "example.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To slice columns `a` and `c` we'll use a similar syntax to the dictionary access, shown before, but instead we will ask for a list of columns instead of a single one, e.g. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example[['a', 'c']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also slice rows using a `list`-like syntax. Note you are __required__ to specify a slice (something containing '`:`'). For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeroth row only\n",
    "example[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First row to end\n",
    "example[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every other row\n",
    "example[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will fail with `KeyError`, because you are requesting key based access\n",
    "example[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More Complicated Access Patterns\n",
    "---\n",
    "\n",
    "You can narrow down rows and columns using `loc`, some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only row 1, columns 'a' and 'c'\n",
    "example.loc[1:1, ['a', 'c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All rows, columns 'a' to 'b'\n",
    "example.loc[:, 'a':'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single row, single column\n",
    "example.loc[0, 'a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "Using `loc` and the `example` DataFrame,\n",
    "\n",
    "1. Can you get every other row, columns `b` to `c`?\n",
    "2. Can you get the last row, all columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "`loc` is all about index/key access, what if the indices are characters? Run the following cell and then complete the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]}, index=['A', 'B', 'C'])\n",
    "example2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "Use `loc` and DataFrame `example2`, to\n",
    "\n",
    "1. Get rows `B` to `C` and columns `a` to `b`.\n",
    "2. What happens if you try to access the index numerically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuation\n",
    "\n",
    "To access `example2` w/ numerical values, we need `iloc`.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Using `iloc` and `example2`, get rows `B` to `C` and columns `a` to `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "You can also use the `list` style access I showed before, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2.iloc[[1, 2], [0, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet Another Option\n",
    "---\n",
    "\n",
    "Another way of accessing is by providing a list of indices based on a condition. For example, return rows of `example2` where column `a` is greater than or equal to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2[example2.a >= 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about columns where row `B` is greater than or equal to 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2.loc['B'][example2.loc['B'] >= 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about compound requirements? Rows where column `a` is greater than or equal to 2 and column `b` is less than 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2[(example2.a >= 2) & (example2.b < 6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Indexing and slicing can be very complicated in Pandas. I think we have dwelled on it long enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing Stuff with DataFrames\n",
    "---\n",
    "\n",
    "Run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pd.read_csv('states.bsv', sep='|')\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore some statistics on this DataFrame, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are 50 states in the DataFrame from `count`. The mean population is 6.5 million people in an area of 76 thousand square miles.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "To get the minimum of a column, you could to `DataFrame.<key>.min()` (`max()` is also an option). Using this information,\n",
    "\n",
    "1. Find the state with the smallest population\n",
    "2. Find the state with the largest area\n",
    "3. Find the state with the smallest population\n",
    "4. Find the state with the largest area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding New Data\n",
    "---\n",
    "\n",
    "What if you were really interested in the population density, that is population divided by the area?\n",
    "\n",
    "DataFrame's support _vectorized_ operations. Try the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.Population / states.Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks\n",
    "---\n",
    "\n",
    "1. What is the type of `states.Population / states.Area`? Is that suprising?\n",
    "2. DataFrame's are mutable, therefore you can always add a new key with Series. Store `states.Population / states.Area` in `states` with the key `Density`.\n",
    "3. Which states are the most/least dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing Data\n",
    "---\n",
    "\n",
    "Pandas plugs into `matplotlib` very nicely. I am going to iteratively build a plot which is easy to read. First, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this is something, but not very helpful. What would we like:\n",
    "\n",
    "- Plots for each column separate\n",
    "- X axis should be labeled with the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = states.plot(subplots=True, xticks=states.index)\n",
    "dummy = ax[0].set_xticklabels(states.State.str.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "---\n",
    "\n",
    "1. `subplots=True`: separates the 2 plots from one another\n",
    "2. `xticks=states.index`: sets all of the points on the x-axis\n",
    "3. `ax = ...`: is a list containing both plots\n",
    "4. `ax[0].set_xticklables` changes the numeric index to the State name, should only be necessary for the 0th plot\n",
    "5. `states.State.str.strip()` is an artifact from the way I made the bsv file, we will discuss string manipulation next\n",
    "6. `dummy = ...`, I use this to supress the output from `set_xticklabels`\n",
    "\n",
    "\n",
    "Neat, but I can't read the labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = states.plot(subplots=True, xticks=states.index, figsize=(20, 10))\n",
    "dummy = ax[0].set_xticklabels(states.State.str.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plots are a little awkward because each point is independent. We should switch to a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = states.plot(subplots=True, xticks=states.index, figsize=(20, 10), kind='bar')\n",
    "dummy = ax[0].set_xticklabels(states.State.str.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "---\n",
    "\n",
    "- `kind=bar` will get us the bar chart\n",
    "\n",
    "Tasks\n",
    "---\n",
    "\n",
    "1. You can also call `plot` on `Series`. Call a `Series` style plot on `Density` with appropriate x labels and readable size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying DataFrames\n",
    "---\n",
    "\n",
    "So, we have been calling `states.State.str.strip()` to generate reasonable x labels. What is going on there? Try the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_string = states.State.loc[0]\n",
    "state_string, len(states.State.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len('Alabama')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, there is a ton of empty space at the end of the state's name for some reason. Let's pretend I didn't do this on purpose and I would like to fix and write a new bsv file. The `str` object has a ton of useful functions for string manipulation. In this case, we want to `strip` off the whitespace, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_string = state_string.strip()\n",
    "state_string, len(state_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I need to do this on the entire DataFrame. How can I do that?\n",
    "\n",
    "As usual, there are a few options:\n",
    "\n",
    "- Apply a lambda function to the Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.State.apply(lambda s: s.strip()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Or__, access the `.str` representation of the Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.State.str.strip().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "I use `.head()` above to reduce the amount of output. Both of the above options return a `Series` of type (`object`) and the latter is preferred for string operations but only work for string manipulations! The `apply` + `lambda` syntax is more general. We will explore it more shortly.\n",
    "\n",
    "The 2 previous cells didn't modify the data in the dataframe, it returned a Series and we have to do the assignment ourselves\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Call the `str` style `strip` function on the `State Series` and store it back into the DataFrame `states`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you should be able to make the plot with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = states.Density.plot(xticks=states.index, figsize=(20, 10), kind='bar')\n",
    "dummy = ax.set_xticklabels(states.State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply + Lambda\n",
    "---\n",
    "\n",
    "\n",
    "I want to briefly show you a decent idiom for doing more complicated work on a Series.\n",
    "\n",
    "This is a contrived example, but it shows the utility of `apply` + `lambda`.\n",
    "\n",
    "What if we wanted wanted to figure out if all letters A-Z are in the names of the states? First, we could create a `set` of characters in each state's name: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_of_chars(s):\n",
    "    return set(list(s.lower()))\n",
    "\n",
    "series_of_sets = states.State.apply(lambda s: set_of_chars(s))\n",
    "series_of_sets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to do something a little fancy here. Functional programming is a powerful tool for something like this. I want to take the `list` of `set`s and convert it to one set. First, to combine two sets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {1, 2, 3}\n",
    "b = {2, 3}\n",
    "a.union(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to \"reduce\" the `list` of `set`s by taking the union of each entry, something like the following:\n",
    "\n",
    "1. `temporary_set = <zeroth entry>.union(<first entry>)`\n",
    "2. `temporary_set = temporary_set.union(<second entry>)`\n",
    "3. `temporary_set = temporary_set.union(<third entry>)`\n",
    "4. Repeat this until there are no more entries and return `temporary_set`\n",
    "\n",
    "We use an anonymous function which takes 2 variables and takes the union between them. We apply that anonymous function to the `series_of_sets` with a call to `reduce`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "characters_used_in_states_names = reduce(lambda x, y: x.union(y), series_of_sets)\n",
    "characters_used_in_states_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one issue! `' '` isn't a character of the alphabet, remove it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_used_in_states_names.remove(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(characters_used_in_states_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One character is missing, which one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "\n",
    "alphabet_set = set(list(ascii_lowercase))\n",
    "alphabet_set.difference(characters_used_in_states_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "---\n",
    "\n",
    "- `ascii_lowercase` is a string with all characters of the alphabet, i.e. `abcdefghijklmnopqrstuvwxyz`\n",
    "\n",
    "The concepts of reductions and anonymous functions are defined and applied often in the world of functional programming. Learning functional concepts can greatly reduce the amount of code you right in your research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing Files\n",
    "---\n",
    "\n",
    "csv files are a pretty standard way to share files, we can write a csv to a file with:\n",
    "\n",
    "```python\n",
    "<DataFrame>.to_csv(<filename>, index=None)\n",
    "```\n",
    "\n",
    "I tend to ignore the index because by default pandas will create a numeric index for you.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Write your `states` DataFrame to a file called \"intro.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping Up\n",
    "---\n",
    "\n",
    "We went over a lot of useful functionality in Pandas to get you started, but honestly there is so much more to cover. I learn something new about Pandas every week. My suggestion is to just default use Pandas when you do everything and learn on the fly.\n",
    "\n",
    "### Documentation Resources\n",
    "\n",
    "- Main documentation page: https://pandas.pydata.org/pandas-docs/stable/\n",
    "- Working with text data: https://pandas.pydata.org/pandas-docs/stable/text.html\n",
    "- Indexing and selecting data: https://pandas.pydata.org/pandas-docs/stable/indexing.html\n",
    "- Computations, statistics, aggregation (reduction with numpy functions): https://pandas.pydata.org/pandas-docs/stable/computation.html\n",
    "- Visualizations: https://pandas.pydata.org/pandas-docs/stable/visualization.html\n",
    "\n",
    "### Quick Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"\", width=760, height=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
